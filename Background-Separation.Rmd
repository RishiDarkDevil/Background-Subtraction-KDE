---
title: "Background Separation"
author: "Rishi Dey Chowdhury"
date: "1/3/2022"
output: 
  html_document:
    keep_md: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(ggplot2)
library(ggpubr)
library(knitr)
library(kableExtra)
library(magrittr)
library(imager)
options(dplyr.summarise.inform = FALSE)
```

# INTRODUCTION

**Foreground Detection is the process of detecting changes in image sequences(Or Video). Background Separation is any technique which allows an image's foreground(or moving object or object to be focused) to be extracted for further processing(eg. object recognition, etc.)**. With the ever increasing demand for better security features and rising computing power, better object tracking, background separation for security or surveillance or still video cameras has become almost an integral part for automated motion or subject detection or video processing.

**A Grayscale(Color) Video, after all, is nothing but a set of 2D matrices(three sets of 2D matrices) stitched together into 3D matrix, where 3rd dimension is time or frame i.e. single channel(3 channels -RGB) of intensity values(0 to 1, both inclusive)**. So, there are parts of videos where the pixel intensity doesn't change at all or changes but very little, whereas the parts where the moving object passes there are high and steep change in the pixel intensities. We can thus model each pixel intensity wrt time and take advantage of the change of the pdf we fit to each pixel of the video over time.

# IDEA & METHOD

Video is a set of 2D Images. Think of each pixel of the image and observe it over time, we now have a sample of intensity values of that pixel over time. Let this sample be $x_1, x_2,\dots, x_N$. We can obtain **the estimate of pixel intensity values by using kernel density estimation**. Given the observed $x_t$ at time $t$, we can estimate probability density function of the observation as,
$$\hat{f}(x_t) = \frac{1}{N}\sum_{i=1}^N K_\sigma(x_t-x_i)$$
where $K_\sigma$ is a kernel function with bandwidth $\sigma$. In our case we will using Normal Kernel with $\sigma = (\frac{4}{5})^{\frac{1}{7}}N^{-\frac{1}{7}}$. Here $N$ is the sample size.

Now, the pixels which have the moving object will have higher pdf value evaluated in that frame compared to the parts which are still and hence assuming to form the background. We **choose the pixel values for a frame whose pdf exceeds some preset threshold as the background**.

# APPLICATION

Here we apply the above described method on some surveillance and traffic videos.
- We have the following surveillance footage. We consider the 100th frame for our application here.
```{r bg_sep_func}
# Grayscale Plot
background.separat.frame.KDE <- function(filename, frame, th = 0.05){
  require(imager)
  
  # Loading the video
  if(typeof(filename) != "double")
    vid <- load.video(filename)
  else
    vid <- filename
  
  # Separated Image
  prob.kde <<- matrix(0, nrow = dim(vid)[1], ncol = dim(vid)[2])
  
  # Filling in the kde values for the kth frame
  N <- dim(vid)[3]
  sig.opt <- ((0.8/N)^(1/7))
  k <- frame
  for (i in 1:dim(vid)[1]) {
    for (j in 1:dim(vid)[2]) {
      r <- vid[i,j,,1]
      prob.kde[i,j] <<- (1/(N*((2*pi)^1.5)*sig.opt))*sum(exp(-((r-r[k])^2)/(2*(sig.opt^2))))
    }
  }
  
  # Setting the separation color
  sep.img <- vid[,,k,]
  for (i in 1:dim(sep.img)[1]) {
    for (j in 1:dim(sep.img)[2]) {
      if((prob.kde[i,j] >= th))
        sep.img[i,j,] <- sep.img[i,j,]/5
    }
  }
  sep.img <- as.cimg(sep.img)
  return(sep.img)
}

# Prob Plot
background.separat.frame.KDE.prob <- function(filename, frame, th = 0.05){
  require(imager)
  
  # Loading the video
  if(typeof(filename) != "double")
    vid <- load.video(filename)
  else
    vid <- filename
  
  # Separated Image
  prob.kde <<- matrix(0, nrow = dim(vid)[1], ncol = dim(vid)[2])
  
  # Filling in the kde values for the kth frame
  N <- dim(vid)[3]
  sig.opt <- ((0.8/N)^(1/7))
  k <- frame
  for (i in 1:dim(vid)[1]) {
    for (j in 1:dim(vid)[2]) {
      r <- vid[i,j,,1]
      prob.kde[i,j] <<- (1/(N*((2*pi)^1.5)*sig.opt))*sum(exp(-((r-r[k])^2)/(2*(sig.opt^2))))
    }
  }
  
  # Prob Plot
  #cat("Info:\n", "Min. Prob: ", min(prob.kde),"\n", "Max. Prob: ", max(prob.kde), '\n')
  prob.kde[prob.kde >= th] = 1
  return(t(1-prob.kde))
}
```

```{r human_pic_ori, fig.asp=1, fig.width=12, warning=FALSE, cache=TRUE}
vid <- load.video("shortVideo.mp4")
plot(grayscale(as.cimg(vid[,,100,])), main = "100th Frame from Household Security Camera")
```


![Security Video](human.gif)

- We will apply the above method discussed on this footage. We first take a look at the density values obtained from KDE of the pixel at row = 228, col = 63 over time frame from 90 to 110. It is clearly visible how the **background pixel at (3,3)'s KDE density estimates over time remain almost same and high, during motion the KDE density estimates drops to a low value. We used threshold value of 0.123** 
```{r calc_prob_changes, cache=TRUE}
prob.changes.motion <- rep(0, length(seq(90, 110, by= 1)))
prob.changes.bg <- rep(0, length(seq(90, 110, by= 1)))
j <- 1
for(i in seq(90, 110, by= 1)){
  background.separat.frame.KDE.prob(vid, i, 0.123)
  prob.changes.motion[j] <- prob.kde[228, 63]
  prob.changes.bg[j] <- prob.kde[3,3]
  j <- j+1
}
```

```{r kde_time_prob_change_plot, fig.asp=1, fig.width=12}
prob.change.data <- tibble(time = 90:110, prob.mot = prob.changes, prob.bg = prob.changes.bg)
prob.change.data %>%
  gather(prob.bg, prob.mot, key = "Class", value = "prob") %>%
  ggplot(aes(time, prob, color = Class)) +
  geom_smooth(formula = 'y~x', method = 'loess', se = FALSE)  +
  geom_abline(slope = 0, intercept = 0.123, size = 2, color = "green") +
  labs(
    x = "Frames(Time)",
    y = "Probabilities",
    color = "Class"
  ) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5), panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"), strip.background = element_blank()) +
  ggtitle("Change in KDE Probability Estimates at (228, 63) and (3,3) pixel at time of motion")
  
```

- Now, we take a look at the background separated 100th frame. It performs really good as can be seen below.
```{r run_func_human, warning=FALSE, cache=TRUE}
sep1 <- background.separat.frame.KDE("shortVideo_gray.mp4", 100, 0.123)
```

```{r background_sep_frame_plot, fig.asp=1, fig.width=12, warning=FALSE}
par(mfrow = c(2,2))
plot(grayscale(as.cimg(vid[,,100,])), main = "Original Frame")
plot(sep1, main = "Background Separated Frame")
plot(as.cimg((1-prob.kde)), main = "Density Values of Frame")
prob.kde1 <- prob.kde
prob.kde1[prob.kde1 >= 0.123] <- 1
prob.kde1[prob.kde1 < 0.123] <- 0
plot(as.cimg((1-prob.kde1)), main = "Density Values of Frame cutoff at Threshold")
par(mfrow = c(1,1))
```

- We consider another video footage of traffic on a road at the 20th Frame. The main 3 cars and the density plot without threshold is almost perfect in separating background. The jagged threshold plot is dependent on the threshold and varies with sitation. We can use an adaptive method to set the threshold for better performance.
```{r traffic_pic_ori, fig.asp=1, fig.width=12, warning=FALSE, cache=TRUE}
vid <- load.video("traffic2.mp4")
plot(grayscale(as.cimg(vid[,,15,])), main = "15th Frame from Traffic Surveillance Camera")
```
![Traffic Surveillance](traffic.gif)

```{r run_fun_traffic, fig.asp=1, fig.width=12, warning=FALSE, cache=TRUE}
sep1 <- background.separat.frame.KDE("traffic_gray.mp4", 15, 0.099)
```

```{r background_sep_frame_plot_traffic, fig.asp=1, fig.width=12, warning=FALSE}
par(mfrow = c(2,2))
plot(grayscale(as.cimg(vid[,,15,])), main = "Original Frame")
plot(sep1, main = "Background Separated Frame")
plot(as.cimg((1-prob.kde)), main = "Density Values of Frame")
prob.kde1 <- prob.kde
prob.kde1[prob.kde1 >= 0.098] <- 1
plot(as.cimg((1-prob.kde1)), main = "Density Values of Frame cutoff at Threshold")
par(mfrow = c(1,1))
```

This wraps up the application of our KDE Method for moving object detection.

# CONCLUSION

We can use this method in:
- Security and Surveillance cameras to detect motion.
- Motion and Object detection.
- Enhancing and Focusing on region of action.
- It is comparatively computationally fast.
- It is immune to slight changes in background

Drawbacks:
- It fails to use the spatial correlation.
- It fails to detect entire object clearly at difficult situations.
